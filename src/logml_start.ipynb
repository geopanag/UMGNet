{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np\n",
    "import json \n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Causal Estimates with Limited Supervision\n",
    "In this notebook we:\n",
    "\n",
    "- Utilize a graph neural network to predict the effect of a marketing campaign to the user's consumption.\n",
    "\n",
    "- Evaluate the impact of supervision i.e. how many users have already participated in the campaign and what was the observed outcome.\n",
    "\n",
    "- We compare our model with standard causal machine learning methods.\n",
    "\n",
    "- We evaluate the method in terms of both uplift and accuracy metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  (user, buys, product)={\n",
       "    edge_index=[2, 14543339],\n",
       "    treatment=[14543339],\n",
       "  },\n",
       "  user={\n",
       "    x=[180653, 7],\n",
       "    t=[180653],\n",
       "    y=[180653],\n",
       "  },\n",
       "  products={ num_products=40542 }\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.load(\"/Users/georgepanagopoulos/Desktop/research/causal_inference/data/retailhero/processed/data.pt\")[0]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "class BipartiteSAGE2mod(torch.nn.Module):\n",
    "    def __init__(self, nfeat:int, nproduct:int , hidden_channels:int , out_channels: int, num_layers:int, dropout_rate:float =0):\n",
    "        super().__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "\n",
    "        self.user_embed = nn.Linear(nfeat, hidden_channels )\n",
    "        self.item_embed =  nn.Linear(nproduct, hidden_channels)\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "\n",
    "        for _ in range(num_layers):\n",
    "            self.convs.append(SAGEConv((-1,-1), hidden_channels))\n",
    "            \n",
    "        #self.lin_hetero = Linear(hidden_channels, out_channels)\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.hidden_common1 = nn.Linear(hidden_channels + num_layers*hidden_channels, hidden_channels)\n",
    "        self.hidden_common2 = nn.Linear(hidden_channels, hidden_channels)\n",
    "\n",
    "        self.hidden_control = nn.Linear(hidden_channels, int(hidden_channels/2))\n",
    "        self.hidden_treatment = nn.Linear(hidden_channels, int(hidden_channels/2))\n",
    "\n",
    "        self.out_control = nn.Linear( int(hidden_channels/2), out_channels)\n",
    "        self.out_treatment = nn.Linear( int(hidden_channels/2), out_channels)\n",
    "\n",
    "        #self.lin = Linear(hidden_channels, out_channels)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        #self.bn_hidden = nn.BatchNorm1d(hidden_channels)\n",
    "        \n",
    "        #self.bn_out = nn.BatchNorm1d(nfeat + hidden_channels + hidden_channels)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, xu: torch.tensor, xp:torch.tensor, edge_index:torch._tensor):\n",
    "        out = [] \n",
    "        xu = self.user_embed(xu)\n",
    "        xp = self.item_embed(xp)\n",
    "\n",
    "        out.append(xu)\n",
    "\n",
    "        embeddings = torch.cat((xu,xp), dim=0) \n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            embeddings = self.activation(self.convs[i](embeddings, edge_index))\n",
    "            #embeddings = self.dropout(embeddings)\n",
    "            #embeddings = self.bn_hidden(embeddings)\n",
    "            \n",
    "            out.append(embeddings[:xu.shape[0]])            \n",
    "        \n",
    "        out = torch.cat( out, dim=1)\n",
    "        \n",
    "        hidden = self.dropout(self.activation(self.hidden_common1(out)))\n",
    "        hidden = self.dropout(self.activation(self.hidden_common2(hidden)))\n",
    "        \n",
    "        # separate treatment and control \n",
    "        hidden_1t0 = self.dropout(self.activation(self.hidden_control(hidden)))\n",
    "        hidden_1t1 = self.dropout(self.activation(self.hidden_treatment(hidden)))\n",
    "\n",
    "        out_2t0 = self.activation(self.out_control(hidden_1t0))\n",
    "        out_2t1 = self.activation(self.out_treatment(hidden_1t1))\n",
    "        \n",
    "        \n",
    "        return out_2t1, out_2t0, hidden_1t1, hidden_1t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def outcome_regression_loss(t_true: torch.tensor,y_treatment_pred: torch.tensor, y_control_pred: torch.tensor, y_true: torch.tensor) -> torch.tensor:\n",
    "    \"\"\"\n",
    "    Compute mse for treatment and control output layers using treatment vector for masking out the counterfactual predictions\n",
    "    \"\"\"\n",
    "    loss0 = torch.mean((1. - t_true) * F.mse_loss(y_control_pred.squeeze(), y_true, reduction='none')) \n",
    "    loss1 = torch.mean(t_true *  F.mse_loss(y_treatment_pred.squeeze(), y_true, reduction='none') )\n",
    "\n",
    "    return loss0 + loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uplift_score(prediction, treatment, target, rate=0.2) -> float:\n",
    "    \"\"\"\n",
    "    From https://ods.ai/competitions/x5-retailhero-uplift-modeling/data\n",
    "    Order the samples by the predicted uplift. \n",
    "    Calculate the average ground truth outcome of the top rate*100% of the treated and the control samples.\n",
    "    Subtract the above to get the uplift. \n",
    "    \"\"\"\n",
    "    order = np.argsort(-prediction)\n",
    "    treatment_n = int((treatment == 1).sum() * rate)\n",
    "    treatment_p = target[order][treatment[order] == 1][:treatment_n].mean()\n",
    "\n",
    "    control_n = int((treatment == 0).sum() * rate)\n",
    "    control_p = target[order][treatment[order] == 0][:control_n].mean()\n",
    "    score = treatment_p - control_p\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with reverse k-fold for semi-supervision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/georgepanagopoulos/Desktop/research/causal_inference/code/UMGNet/src/config_RetailHero.json', 'r') as config_file:\n",
    "        config = json.load(config_file)\n",
    "        \n",
    "n_hidden = config[\"n_hidden\"]\n",
    "no_layers = config[\"no_layers\"]\n",
    "out_channels = config[\"out_channels\"]\n",
    "num_epochs = config[\"num_epochs\"]\n",
    "lr = config[\"lr\"]\n",
    "results_file_name = config['results_file_name']\n",
    "model_file_name = config[\"model_file\"]\n",
    "early_thres = config['early_stopping_threshold']\n",
    "l2_reg = config['l2_reg']\n",
    "with_lp = config['with_label_prop'] == 1\n",
    "number_of_runs = config['number_of_runs']\n",
    "dropout = config['dropout']\n",
    "k = 10\n",
    "seed = 1\n",
    "validation_fraction = 5\n",
    "patience = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "xp = torch.eye(data['products']['num_products'])\n",
    "#xu = data['user']['x']\n",
    "#edge_index = data['user','buys','product']\n",
    "\n",
    "criterion = outcome_regression_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=abs(k), shuffle=True, random_state=seed)\n",
    "result_fold = []\n",
    "if with_lp:   \n",
    "    dummy_product_labels = torch.zeros([xp.shape[0],1]).to(device).squeeze()\n",
    "\n",
    "for train_indices, test_indices in kf.split(data['user']['x']):\n",
    "    test_indices, train_indices = train_indices, test_indices\n",
    "    break \n",
    "\n",
    "# split the test indices to test and validation \n",
    "val_indices = train_indices[:int(len(train_indices)/validation_fraction)]\n",
    "train_indices = train_indices[int(len(train_indices)/validation_fraction):]\n",
    "\n",
    "## Keep the graph before the treatment and ONLY the edges of the the train nodes (i.e. after the treatment)\n",
    "# remove edge_index_df[ edge_index_df['user'].isin(train_indices)  if you dont want edges from train set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "model = BipartiteSAGE2mod(data['user']['x'].shape[1], xp.shape[1] , n_hidden, out_channels, no_layers, dropout)\n",
    "optimizer = Adam(model.parameters(), lr=lr, weight_decay = l2_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     9,      9,      9,  ..., 180652, 180652, 180652],\n",
       "        [     7,     21,     35,  ...,  26027,  32927,  35206]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['user','buys','product']['edge_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask_expanded = data['user','buys','product']['treatment'].expand_as(data['user','buys','product']['edge_index'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.isin(data['user','buys','product']['edge_index'][0, :], torch.tensor(train_indices) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index_up_current = data['user','buys','product']['edge_index'][ : , (~data['user','buys','product']['treatment']) | (mask) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### THIS needs work\n",
    "#edge_index_up_current = edge_index[:, edge_index_df[ edge_index_df['user'].isin(train_indices) | edge_index_df['T']==0 ].index.values]\n",
    "# make unsupervised and add num_nodes for bipartite message passing\n",
    "edge_index_up_current[1] = edge_index_up_current[1]+ data['user']['x'].shape[0]\n",
    "edge_index_up_current = torch.cat([edge_index_up_current,edge_index_up_current.flip(dims=[0])],dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# init params\n",
    "out = model( data['user'][\"x\"] , xp , edge_index_up_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "def train(mask: torch.tensor, model, data: pyg.data.Data, xp, optimizer: Optimizer, \n",
    "                     criterion: Callable[[torch.tensor, torch.tensor, torch.tensor, torch.tensor], torch.tensor] ):\n",
    "      model.train()\n",
    "      optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "      out_treatment, out_control, hidden_treatment, hidden_control = model(data['user'][\"x\"], xp, edge_index_up_current)\n",
    "      loss = criterion(data['user']['t'][mask], out_treatment[mask], out_control[mask], data['user'][\"y\"][mask])\n",
    "     \n",
    "      loss.backward()  # Derive gradients.\n",
    "      optimizer.step()  # Update parameters based on gradients.\n",
    "      return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(mask: torch.tensor, model , data: pyg.data.Data):\n",
    "      model.eval()\n",
    "      out = model(data.x,data.edge_index)\n",
    "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "      correct = pred[mask] == data.y[mask]  # Check against ground-truth labels.\n",
    "      acc = int(correct.sum()) / int(mask.sum())  # Derive ratio of correct predictions.\n",
    "      return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = train(train_mask, model, data, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_acc = 0 \n",
    "best_test_acc = 0\n",
    "early_stopping = 0\n",
    "\n",
    "# write the results in a file wicth the dataset name on it \n",
    "for epoch in range(num_epochs):\n",
    "    loss = train(train_indices, model, data, optimizer, criterion)\n",
    "\n",
    "    val_acc = test(val_indices, model, data)\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        early_stopping=0\n",
    "        best_val_acc = val_acc\n",
    "        best_test_acc = test(test_indices, model, data)\n",
    "    else:\n",
    "        early_stopping += 1\n",
    "        if early_stopping > patience:\n",
    "            print(\"early stopping..\")\n",
    "            break\n",
    "            \n",
    "    if epoch%50==0:\n",
    "        test_acc = test(test_indices, model, data)\n",
    "        train_acc = test(train_indices, model, data)\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Tra: {train_acc:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n",
    "        #log.write(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Tra: {train_acc:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}\\n')\n",
    "        #log.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "out_treatment, out_control, hidden_treatment, hidden_control = model(xu, xp, edge_index_up_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(mask: torch.tensor, model , data: pyg.data.Data):\n",
    "    model.eval()\n",
    "    out = model(data.x,data.edge_index)\n",
    "    pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "    correct = pred[mask] == data.y[mask]  # Check against ground-truth labels.\n",
    "    acc = int(correct.sum()) / int(mask.sum())  # Derive ratio of correct predictions.\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------ Evaluating\n",
    "treatment_test = treatment[test_indices].detach().cpu().numpy()\n",
    "outcome_test = outcome[test_indices].detach().cpu().numpy()\n",
    "out_treatment = out_treatment.detach().cpu().numpy()\n",
    "out_control = out_control.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "uplift = out_treatment[test_indices] - out_control[test_indices]\n",
    "uplift = uplift.squeeze()\n",
    "\n",
    "#mse = (uplift.mean() - (outcome_test[treatment_test==1].mean() - outcome_test[treatment_test==0].mean()))**2\n",
    "#print(f'mse {mse}')\n",
    "up40 = uplift_score(uplift, treatment_test, outcome_test,0.4)\n",
    "print(f'up40 {up40}')\n",
    "up20 = uplift_score(uplift, treatment_test, outcome_test,0.2)\n",
    "print(f'up20 {up20}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
